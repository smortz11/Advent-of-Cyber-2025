In today's Advent of Cyber challenge, as the name suggests, we are going to be using Splunk. Splunk is an enterprise grade security information and event manager (SIEM). These are essentially the home of SOC analysts. They aggregate logs using Splunk forwarders on various devices, and uses a high quality search processing language (SPL) to allow for refined searches and high quality log analysis. Today, we will be running a VM with Splunk configured and looking around!

We can go ahead and start our VM. After doing so, we are given a link that is a reverse proxy into the Splunk instance. Clicking it allows us to use Splunk in our web browser. From there, we will be able to continue the room. We are also told that all of our data has been pre-ingested for us to investigate.

We are told to go ahead and search for `index=main` while setting our time to `All time`. Doing so allows us to see all of our logs (assuming that they were not further partitioned into various indices. Main is the default). In the left column, we note that there are two elements in the `sourcetype` field, being `web_traffic` and `firewall_logs`. Let's further refine our search and add `sourcetype=web_traffic`.

We want to further manipulate the Splunk search and see the amount of web traffic requests per day. We can do this with a combined command of `index=main sourcetype=web_traffic | timechart span=1d count | sort by count`. This command, while difficult to construct at first, is easy to see what is happening with. We are scraping all web traffic, subdividing it into one-day increments and counting the amount of traffic per. Then we are sorting by this amount. This may give insight to a user about anomalous activity. The visualization tab, below the search bar, also allows us to, well, visualize the data, which is helpful when parsing large amounts of information. It should be noted that with any command, we can append `| reverse` to reverse the order in which information is presented to us. Our log analysis thus far has shown a large amount of logs on specific days, a feature that we will be investigating.

Beginning our anomaly detection, we can return to the `Events` tab. Here, we can select the `user_agent` field in the left column. We can see that there are several Mozilla variants, which is common. We can also see many that are... concerning. This includes `Havij`, `sqlmap`, etc.

In the `client_ip` field, we can also see that of the hundreds of IP addresses, only one accounts for nearly *half* of the traffic. This suggests anomalous activity. In the `path` field, we can see some concerning paths that were entered for the web traffic as well. `../../etc/passwd` suggests a directory traversal attack. `AND SLEEP(5)--` suggests that the endpoints were being tested for injects.

Let's filter out some traffic that is *probably* not bad. We can do so with a search query like this: `index=main sourcetype=web_traffic user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari* user_agent!=*Firefox*`. Doing so removes about 10k logs from our pool for analysis. It also points to some new insights: there is only one client_ip now. This adversarial IP address is `198.51.100.55`.

Now, let's trace the attack chain. Using the search query `sourcetype=web_traffic client_ip=198.51.100.55 AND path IN ("/.env", "/*phpinfo*", "/.git*") | table _time, path, user_agent, status` will give us commonly attacked paths from the IP address, sorted into a table with the time, path, user_agent, and status code. Doing so verifies a lot of curl and wget user_agents. These were all met with 4XX codes, which means that they did not work for the attacker.

Let's go back to the directory traversal attack we saw earlier. We can search using a query like `sourcetype=web_traffic client_ip=198.51.100.55 AND path="*..*" OR path="*redirect*"`. This will give us logs from the adversarial IP where a path includes `..` or `redirect`. Since `/` is a special character, if we want to search for `../../`, we would actually use `..\/..\/*`. This will return all things that look like `../../<something>`

Let's go back to the adversarial user agents we noted earlier. We can add those to a search query with `sourcetype=web_traffic client_ip=198.51.100.55 AND user_agent IN ("*sqlmap*", "*Havij*") | table _time, path, status`. Doing so verifies the different injections attempted on our endpoints. Some of these come up as `200` status codes, meaning that an inject of some sort likely did occur. A `504` suggests that a successful time-based attack took place.

Let's now look for some exfil attempts. This is the download of (possibly large) files from our network. We can search for this using a query as `sourcetype=web_traffic client_ip=198.51.100.55 AND path IN ("*backup.zip*", "*logs.tar.gz*") | table _time, path, user_agent`. The results indicate a large amount of hits for `logs.tar.gz`, which suggests that tools like wget and curl were used to grab these files.

Moving onto the ransomware staging, we can use a search query `sourcetype=web_traffic client_ip=198.51.100.55 AND path IN ("*bunnylock.bin*", "*shell.php?cmd=*") | table _time, path, user_agent, status`. This will search for the following file types in the path. The presence of these files in the URL verifies the presence of a webshell. The attackers are performing remote code execution. The specific line `/shell.php?cmd=./bunnylock.bin` shows that the binary file was executed remotely.

Let's try to look at some of our C2 comms now. We will be using the firewall logs with the IP address of the web server. `sourcetype=firewall_logs src_ip=10.10.1.5 and dest_ip=198.51.100.55 AND action="ALLOWED" | table _time, action, protocol, src_ip, dest_ip, dest_port, reason`. Parsing this, we can see it as allowed traffic going from our web server to our adversary. And return, it does. There is a ton of C2 exfil traffic. After establishing the web shell, the attacker was able to connect back to their own server for communication that is less likely to be blocked by firewalls and other security devices.

Finally, let's try to check the volume of exfiltrated data. Since we know that there have been communications from our compromised server to the attacker, we can check the communications between the two and look at the actual data being sent. `sourcetype=firewall_logs src_ip="10.10.1.5" AND dest_ip="198.51.100.55" AND action="ALLOWED" | stats sum(bytes_transferred) by src_ip`. This gives us the number of bytes, which is the answer to a question below.

Note: actual answers to the questions cannot be provided. Therefore, I will only explain my methodology.

### What is the attacker IP found attacking and compromising the web server?

This was found in an above query and used throughout

### Which day was the peak traffic in the logs? (Format: YYYY-MM-DD)

I accomplished this with the query `sourcetype=web_traffic | timechart span=1d count | sort by count`

### What is the cont of Havij user_agent events found in the logs?

This was done with the query `sourcetype=web_traffic user_agent="*Havij*"`.

### How many path traversal attempts to access sensitive files on the server were observed?

I found this number with `sourcetype=web_traffic client_ip="198.51.100.55" AND path="*..*"`.

### Examine the firewall logs. How many bytes were transferred to the C2 server IP from the compromised web server?

This was found in the final paragraph